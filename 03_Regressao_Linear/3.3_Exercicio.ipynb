{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício\n",
    "\n",
    "Você nem sempre obterá dados em um formato conveniente, muitas vezes você terá que lidar com dados não numéricos, como nomes de clientes ou códigos postais, nomes de países, etc ...\n",
    "\n",
    "\n",
    "O Spark possui vários métodos integrados para lidar com essas transformações, verifique todos aqui: http://spark.apache.org/docs/latest/ml-features.html\n",
    "\n",
    "Vamos ver alguns exemplos de tudo isso!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('data').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('fake_customers.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-----+\n",
      "|   Name|     Phone|Group|\n",
      "+-------+----------+-----+\n",
      "|   John|4085552424|    A|\n",
      "|   Mike|3105552738|    B|\n",
      "| Cassie|4085552424|    B|\n",
      "|  Laura|3105552438|    B|\n",
      "|  Sarah|4085551234|    A|\n",
      "|  David|3105557463|    C|\n",
      "|   Zach|4085553987|    C|\n",
      "|  Kiera|3105552938|    A|\n",
      "|  Alexa|4085559467|    C|\n",
      "|Karissa|3105553475|    A|\n",
      "+-------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursos de dados\n",
    "\n",
    "### StringIndexer\n",
    "\n",
    "Freqüentemente, temos que converter informações de string em informações numéricas como um recurso categórico. Isso é feito facilmente com o Método StringIndexer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-----------------+\n",
      "|user_id|category|indice_categorico|\n",
      "+-------+--------+-----------------+\n",
      "|      0|       a|              0.0|\n",
      "|      1|       b|              2.0|\n",
      "|      2|       c|              1.0|\n",
      "|      3|       a|              0.0|\n",
      "|      4|       a|              0.0|\n",
      "|      5|       c|              1.0|\n",
      "+-------+--------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "df = spark.createDataFrame(\n",
    "    [(0, \"a\"), (1, \"b\"), (2, \"c\"), (3, \"a\"), (4, \"a\"), (5, \"c\")],\n",
    "    [\"user_id\", \"category\"])\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"category\", outputCol=\"indice_categorico\")\n",
    "indexed = indexer.fit(df).transform(df)\n",
    "indexed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VectorAssembler\n",
    "\n",
    "VectorAssembler é um transformador que combina uma determinada lista de colunas em uma única coluna de vetor. É útil para combinar recursos brutos e recursos gerados por diferentes transformadores de recursos em um único vetor de recursos, a fim de treinar modelos de ML como regressão logística e árvores de decisão. VectorAssembler aceita os seguintes tipos de coluna de entrada: todos os tipos numéricos, tipo booleano e tipo de vetor. Em cada linha, os valores das colunas de entrada serão concatenados em um vetor na ordem especificada.\n",
    "\n",
    "Suponha que temos um DataFrame com as colunas id, hour, mobile, userFeatures e clicked:\n",
    "\n",
    "     id | hour | mobile | userFeatures     | clicked\n",
    "    ----|------|--------|------------------|---------\n",
    "     0  | 18   | 1.0    | [0.0, 10.0, 0.5] | 1.0\n",
    "     \n",
    "userFeatures é uma coluna vetorial que contém três recursos do usuário. Queremos combinar recursos de hora, dispositivo móvel e usuário em um único vetor de recurso chamado features e usá-lo para prever os cliques ou não. Se definirmos as colunas de entrada de VectorAssembler como hora, móvel e userFeatures e a coluna de saída como recursos, após a transformação, devemos obter o seguinte DataFrame:\n",
    "\n",
    "     id | hour | mobile | userFeatures     | clicked | features\n",
    "    ----|------|--------|------------------|---------|-----------------------------\n",
    "     0  | 18   | 1.0    | [0.0, 10.0, 0.5] | 1.0     | [18.0, 1.0, 0.0, 10.0, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------+--------------+-------+\n",
      "| id|hour|mobile|  userFeatures|clicked|\n",
      "+---+----+------+--------------+-------+\n",
      "|  0|  18|   1.0|[0.0,10.0,0.5]|    1.0|\n",
      "+---+----+------+--------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "dataset = spark.createDataFrame(\n",
    "    [(0, 18, 1.0, Vectors.dense([0.0, 10.0, 0.5]), 1.0)],\n",
    "    [\"id\", \"hour\", \"mobile\", \"userFeatures\", \"clicked\"])\n",
    "dataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assembled columns 'hour', 'mobile', 'userFeatures' to vector column 'features'\n",
      "+--------------------+-------+\n",
      "|            features|clicked|\n",
      "+--------------------+-------+\n",
      "|[18.0,1.0,0.0,10....|    1.0|\n",
      "+--------------------+-------+\n",
      "\n",
      "+---+----+------+--------------+-------+--------------------+\n",
      "| id|hour|mobile|  userFeatures|clicked|            features|\n",
      "+---+----+------+--------------+-------+--------------------+\n",
      "|  0|  18|   1.0|[0.0,10.0,0.5]|    1.0|[18.0,1.0,0.0,10....|\n",
      "+---+----+------+--------------+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"hour\", \"mobile\", \"userFeatures\"],\n",
    "    outputCol=\"features\")\n",
    "\n",
    "output = assembler.transform(dataset)\n",
    "print(\"Assembled columns 'hour', 'mobile', 'userFeatures' to vector column 'features'\")\n",
    "output.select(\"features\", \"clicked\").show()\n",
    "output.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
